{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da19e4d4",
   "metadata": {},
   "source": [
    "# Классификация обзоров фильмов\n",
    "\n",
    "\n",
    "\n",
    "# Цель\n",
    "Классификация последовательностей - это проблема прогнозирующего моделирования, когда у вас есть некоторая последовательность входных данных в пространстве или времени, и задача состоит в том, чтобы предсказать категорию для последовательности.\n",
    "Проблема усложняется тем, что последовательности могут различаться по длине, состоять из очень большого словарного запаса входных символов и могут потребовать от модели изучения долгосрочного контекста или зависимостей между символами во входной последовательности. \n",
    "\n",
    "В данной лабораторной работе также будет использоваться датасет IMDb, однако\n",
    "обучение будет проводиться с помощью рекуррентной нейронной сети.\n",
    "\n",
    "# Задачи\n",
    "\n",
    "* Ознакомиться с рекуррентными нейронными сетями\n",
    "* Изучить способы классификации текста\n",
    "* Ознакомиться с ансамблированием сетей\n",
    "* Построить ансамбль сетей, который позволит получать точность не менее 97%\n",
    "\n",
    "# Выполнение работы\n",
    "\n",
    "\n",
    "### Подключение модулей\n",
    "Набор данных imdb уже входит в состав Keras в форме набора из четырех массивов Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe768b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "#Для стакинга моделей \n",
    "from tensorflow.keras.models import load_model\n",
    "from numpy import dstack\n",
    "from os import makedirs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e88c87f",
   "metadata": {},
   "source": [
    "Напишем функцию для загрузки тренеровочных и тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9082f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # Загружаем данные\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "    print('x_train shape:',x_train.shape)\n",
    "    print('x_test shape:',x_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4c76e",
   "metadata": {},
   "source": [
    "Создадим функцию которая преобразует наши данные в необходимы вид"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9bbf6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pixels(train, test):\n",
    "    train_norm = pad_sequences(train, maxlen=100, value = 0.0)\n",
    "    test_norm = pad_sequences(test, maxlen=100, value = 0.0)\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f3a85",
   "metadata": {},
   "source": [
    "Создадим модель обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f01c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    #Превращает положительные целые числа (индексы) в плотные векторы фиксированного размера.\n",
    "    model.add(Embedding(10000, 50, input_length=100))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv1D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(Conv1D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(LSTM(128))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a7201",
   "metadata": {},
   "source": [
    "Функция прогона и сохранения моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a232953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_modelss():\n",
    "\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    \n",
    "    # create directory for models\n",
    "    makedirs('models')\n",
    "    # fit and save models\n",
    "    n_members = 2\n",
    "    for i in range(n_members):\n",
    "        # fit model\n",
    "        model = define_model()   \n",
    "        #Обучение сети\n",
    "        model.fit(trainX, trainY, epochs=3, batch_size=508, validation_data=(testX, testY), verbose=1)\n",
    " \n",
    "        # save model\n",
    "        filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "        model.save(filename)\n",
    "        print('>Saved %s' % filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea92253",
   "metadata": {},
   "source": [
    "Натренируем модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0502ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000,)\n",
      "x_test shape: (25000,)\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 17s 89ms/step - loss: 0.6794 - accuracy: 0.5378 - val_loss: 0.5585 - val_accuracy: 0.7037\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 3s 53ms/step - loss: 0.4466 - accuracy: 0.7922 - val_loss: 0.4516 - val_accuracy: 0.7824\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 3s 53ms/step - loss: 0.3102 - accuracy: 0.8671 - val_loss: 0.3825 - val_accuracy: 0.8288\n",
      ">Saved models/model_1.h5\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 7s 70ms/step - loss: 0.6861 - accuracy: 0.5322 - val_loss: 0.5555 - val_accuracy: 0.7314\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 3s 53ms/step - loss: 0.4621 - accuracy: 0.7806 - val_loss: 0.4976 - val_accuracy: 0.7625\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 3s 53ms/step - loss: 0.3270 - accuracy: 0.8587 - val_loss: 0.4852 - val_accuracy: 0.7846\n",
      ">Saved models/model_2.h5\n"
     ]
    }
   ],
   "source": [
    "save_all_modelss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89bb91",
   "metadata": {},
   "source": [
    "Создадим функцию загрузки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b7afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57097ae7",
   "metadata": {},
   "source": [
    "Создадим функцию зборки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20603cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_dataset(members, inputX):\n",
    "    stackX = None\n",
    "    for model in members:\n",
    "        # make prediction\n",
    "        yhat = model.predict(inputX, verbose=0)\n",
    "        print (\"Predict\",yhat)\n",
    "        # stack predictions into [rows, members, probabilities]\n",
    "        if stackX is None:\n",
    "            stackX = yhat\n",
    "        else:\n",
    "            stackX = dstack((stackX, yhat))\n",
    "            print (\"Stack predict\", stackX)\n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "    return stackX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee34c77",
   "metadata": {},
   "source": [
    "Функция обучения со всеми моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "802e8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stacked_model(members, inputX, inputY):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # fit standalone model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(stackedX, inputY)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051310e0",
   "metadata": {},
   "source": [
    "Функция предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09bb81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_prediction(members, model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66fd47d",
   "metadata": {},
   "source": [
    "Функцию, которая позволяет ввести пользовательский текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1536cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToInt(text, dimension = 10000):\n",
    "    indexes = imdb.get_word_index()\n",
    "    temp = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            if (indexes[word] < 9998):\n",
    "                temp.append(indexes[word] + 3)\n",
    "        except Exception:\n",
    "            print(\"Введен недопустимый символ\")\n",
    "            temp.append(0)       \n",
    "            continue\n",
    "    while len(temp) < 100:\n",
    "        temp.insert(0,0)\n",
    "    temp = np.array(temp).reshape(-1, 100)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5499908",
   "metadata": {},
   "source": [
    "Функция запуска нашей нейроной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca03e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_harness():\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    \n",
    "    #Загрузка моделей\n",
    "    n_members = 2\n",
    "    members = load_all_models(n_members)\n",
    "    \n",
    "    print('Loaded %d models' % len(members))\n",
    "    \n",
    "    for model in members:\n",
    "        loss, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('Model Accuracy: %.3f' % acc)\n",
    "    \n",
    "    model = fit_stacked_model(members, testX, testY)\n",
    "    \n",
    "    return members, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fa3d1",
   "metadata": {},
   "source": [
    "Ансамблируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a23435d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000,)\n",
      "x_test shape: (25000,)\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      "Loaded 2 models\n",
      "Model Accuracy: 0.829\n",
      "Model Accuracy: 0.785\n",
      "Predict [[0.0549113 ]\n",
      " [0.952798  ]\n",
      " [0.76942307]\n",
      " ...\n",
      " [0.01294683]\n",
      " [0.02541268]\n",
      " [0.19453388]]\n",
      "Predict [[0.86047083]\n",
      " [0.98091024]\n",
      " [0.96378964]\n",
      " ...\n",
      " [0.07352982]\n",
      " [0.51022553]\n",
      " [0.9286893 ]]\n",
      "Stack predict [[[0.0549113  0.86047083]]\n",
      "\n",
      " [[0.952798   0.98091024]]\n",
      "\n",
      " [[0.76942307 0.96378964]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.01294683 0.07352982]]\n",
      "\n",
      " [[0.02541268 0.51022553]]\n",
      "\n",
      " [[0.19453388 0.9286893 ]]]\n"
     ]
    }
   ],
   "source": [
    "members, model = run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3f0d5",
   "metadata": {},
   "source": [
    "Ввод и предикт текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45b18dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_in_ense(members, model):\n",
    "    #Ввод пользователем текст.\n",
    "    indexesList = textToInt(input().split(\" \"))\n",
    "    print (\"-----------\")\n",
    "    print (indexesList)\n",
    "    print (\"-----------\")\n",
    "    il = pad_sequences(indexesList, maxlen=100, value = 0.1)\n",
    "    print (il)\n",
    "    print (\"-----------\")\n",
    "    #t = np.transpose(indexesList)\n",
    "    #a = model.predict(t) \n",
    "    a = stacked_prediction(members, model, il)\n",
    "    #acc = accuracy_score(testY,a)\n",
    "    print('Stacked Test Accuracy: %.3f' % a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a005464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very good movie i am fine\n",
      "-----------\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  55  52  20  13 244 478]]\n",
      "-----------\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  55  52  20  13 244 478]]\n",
      "-----------\n",
      "Predict [[0.30966976]]\n",
      "Predict [[0.98690665]]\n",
      "Stack predict [[[0.30966976 0.98690665]]]\n",
      "Stacked Test Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "inp_in_ense(members, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcaa795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very bad movie\n",
      "-----------\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 55 78 20]]\n",
      "-----------\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 55 78 20]]\n",
      "-----------\n",
      "Predict [[0.04598336]]\n",
      "Predict [[0.9501602]]\n",
      "Stack predict [[[0.04598336 0.9501602 ]]]\n",
      "Stacked Test Accuracy: 0.000\n"
     ]
    }
   ],
   "source": [
    "inp_in_ense(members, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
