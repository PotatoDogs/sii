{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da19e4d4",
   "metadata": {},
   "source": [
    "# Распознавание рукописных символов\n",
    "\n",
    "\n",
    "# Цель\n",
    "Реализовать классификацию черно-белых изображений рукописных цифр (28x28) по 10\n",
    "категориям (от 0 до 9).\n",
    "\n",
    "Набор данных содержит 60,000 изображений для обучения и 10,000 изображений для\n",
    "тестирования.\n",
    "\n",
    "# Задачи\n",
    "\n",
    "* Ознакомиться с представлением графических данных\n",
    "* Ознакомиться с простейшим способом передачи графических данных нейронной\n",
    "сети\n",
    "* Создать модель\n",
    "* Настроить параметры обучения\n",
    "* Написать функцию, позволяющая загружать изображение пользователи и классифицировать его\n",
    "\n",
    "# Выполнение работы\n",
    "\n",
    "\n",
    "### Подключение модулей\n",
    "Набор данных MNIST уже входит в состав Keras в форме набора из четырех массивов Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe768b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy import asarray, argmax\n",
    "from PIL.ImageOps import invert\n",
    "from PIL.Image import open\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a2b21",
   "metadata": {},
   "source": [
    "Здесь train_images и train_labels — это тренировочный набор, то есть данные,\n",
    "необходимые для обучения. После обучения модель будет проверяться тестовым (или\n",
    "контрольным) набором, test_images и test_labels. Изображения хранятся в массивах\n",
    "Numpy, а метки — в массиве цифр от 0 до 9. Изображения и метки находятся в прямом\n",
    "соответствии, один к одному."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d6339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape (60000, 28, 28)\n",
      "train_labels shape (60000,)\n",
      "test_images shape (10000, 28, 28)\n",
      "test_labels shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"train_images shape\", train_images.shape)\n",
    "print(\"train_labels shape\",  train_labels.shape)\n",
    "print(\"test_images shape\", test_images.shape)\n",
    "print(\"test_labels shape\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7039a7b0",
   "metadata": {},
   "source": [
    "Для проверки корректности загрузки достаточно сравнить тестовое изображение с его меткой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2bd5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(train_images[5],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(train_labels[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5499908",
   "metadata": {},
   "source": [
    "Исходные изображения представлены в виде массивов чисел в интервале [0, 255]. Перед обучением их необходимо преобразовать так, чтобы все значения оказались в интервале [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca03e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b231540e",
   "metadata": {},
   "source": [
    "Также необходимо закодировать метки категорий. В данном случае прямое кодирование меток заключается в конструировании вектора с нулевыми элементами со значением 1 в элементе, индекс которого соответствует индексу метки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a3a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f957c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28))) # ВЫравниевание\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc387ff",
   "metadata": {},
   "source": [
    "Чтобы подготовить сеть к обучению, нужно настроить еще три параметра для этапа\n",
    "компиляции:\n",
    "1. функцию потерь, которая определяет, как сеть должна оценивать качество своей работы на обучающих данных и, соответственно, как корректировать ее в правильном направлении;\n",
    "2. оптимизатор — механизм, с помощью которого сеть будет обновлять себя, опираясь на наблюдаемые данные и функцию потерь;\n",
    "3. метрики для мониторинга на этапах обучения и тестирования — здесь нас будет\n",
    "интересовать только точность (доля правильно классифицированных\n",
    "изображений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa1b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade2a04",
   "metadata": {},
   "source": [
    "Теперь можно начинать обучение сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "104d3fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 7s 10ms/step - loss: 0.3105 - accuracy: 0.9115\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1253 - accuracy: 0.9626\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.0875 - accuracy: 0.9738\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0658 - accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0511 - accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac83111dc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c9d294",
   "metadata": {},
   "source": [
    "Теперь проверим, как модель распознает контрольный набор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5caf525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0720 - accuracy: 0.9770\n",
      "test_acc: 0.9769999980926514\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9cdc6",
   "metadata": {},
   "source": [
    "Попробуем запредиктить нашу картинку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1423294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятность 0 = 0.018%\n",
      "Вероятность 1 = 0.015%\n",
      "Вероятность 2 = 0.234%\n",
      "Вероятность 3 = 3.651%\n",
      "Вероятность 4 = 0.021%\n",
      "Вероятность 5 = 0.012%\n",
      "Вероятность 6 = 0.005%\n",
      "Вероятность 7 = 0.004%\n",
      "Вероятность 8 = 96.03%\n",
      "Вероятность 9 = 0.009%\n"
     ]
    }
   ],
   "source": [
    "def customNumber():\n",
    "    img = asarray(invert(open('num.png').convert(mode=\"L\")))\n",
    "    img = img / 255.0\n",
    "    img = img.reshape(-1, 28, 28)\n",
    "    return img\n",
    "x = customNumber()\n",
    "a = model.predict(x)\n",
    "i = 0\n",
    "\n",
    "for el in a[0]:\n",
    "    print(f\"Вероятность {i} = {round(float(el)*100, 3)}%\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1021ee79",
   "metadata": {},
   "source": [
    "При вводе картинки с цифрой 3 все еще может выдаваться неудовлетворительный результат.\n",
    "Поэтому попробуем поменять модель обучения. А именно - вместо Sequential() будем использовать Model(). Разницы в обучении нет, но Model можно более точно скорректировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36278ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 13s 41ms/step - loss: 0.0986 - accuracy: 0.9703\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.0274 - accuracy: 0.9920\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.0179 - accuracy: 0.9947\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.0126 - accuracy: 0.9963\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.0091 - accuracy: 0.9975\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0260 - accuracy: 0.9906\n",
      "test_acc: 0.9905999898910522\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(60000, 28,28,1)\n",
    "test_images = test_images.reshape(10000, 28,28,1)\n",
    "\n",
    "\n",
    "train_images = train_images.astype('float32') # Flatten data to 1D\n",
    "test_images = test_images.astype('float32') # Flatten data to 1D\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution Layer 1\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer01 = Activation('relu')                     # activation\n",
    "model.add(convLayer01)\n",
    "\n",
    "# Convolution Layer 2\n",
    "model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer02)\n",
    "\n",
    "# Convolution Layer 3\n",
    "model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer03 = Activation('relu')                     # activation\n",
    "model.add(convLayer03)\n",
    "\n",
    "# Convolution Layer 4\n",
    "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer04)\n",
    "model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
    "\n",
    "# Fully Connected Layer 5\n",
    "model.add(Dense(512))                                # 512 FCN nodes\n",
    "model.add(BatchNormalization())                      # normalization\n",
    "model.add(Activation('relu'))                        # activation\n",
    "\n",
    "# Fully Connected Layer 6                       \n",
    "model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
    "model.add(Dense(10))                                 # final 10 FCN nodes\n",
    "model.add(Activation('softmax'))                     # softmax activation\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=300)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b14bbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятность 0 = 0.0%\n",
      "Вероятность 1 = 0.0%\n",
      "Вероятность 2 = 0.0%\n",
      "Вероятность 3 = 0.231%\n",
      "Вероятность 4 = 0.0%\n",
      "Вероятность 5 = 0.0%\n",
      "Вероятность 6 = 0.0%\n",
      "Вероятность 7 = 0.0%\n",
      "Вероятность 8 = 99.768%\n",
      "Вероятность 9 = 0.001%\n"
     ]
    }
   ],
   "source": [
    "def customNumber():\n",
    "    img = asarray(invert(open('num.png').convert(mode=\"L\")))\n",
    "    img = img.reshape(-1, 28, 28, 1)\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "x = customNumber()\n",
    "a = model.predict(x)\n",
    "i = 0\n",
    "\n",
    "for el in a[0]:\n",
    "    print(f\"Вероятность {i} = {round(float(el)*100, 3)}%\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23435d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
