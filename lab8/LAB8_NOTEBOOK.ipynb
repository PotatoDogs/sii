{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da19e4d4",
   "metadata": {},
   "source": [
    "# Генерация текста на основе “Алисы в стране чудес”\n",
    "\n",
    "\n",
    "\n",
    "# Цель\n",
    "Рекуррентные нейронные сети также могут быть использованы в качестве генеративных моделей.\n",
    "Это означает, что в дополнение к тому, что они используются для прогнозных моделей (создания прогнозов), они могут изучать последовательности проблемы, а затем генерировать совершенно новые вероятные последовательности для проблемной\n",
    "области.\n",
    "Подобные генеративные модели полезны не только для изучения того, насколько хорошо модель выявила проблему, но и для того, чтобы узнать больше о самой проблемной области.\n",
    "\n",
    "# Задачи\n",
    "\n",
    "* Ознакомиться с генерацией текста\n",
    "* Ознакомиться с системой Callback в Keras\n",
    "\n",
    "# Выполнение работы\n",
    "\n",
    "\n",
    "### Подключение модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe768b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62acae8",
   "metadata": {},
   "source": [
    "Добавим систему Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b22102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"End epoch {} of training\".format(epoch))\n",
    "        prnt_txt(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84beffde",
   "metadata": {},
   "source": [
    "Функция печати сгенерированных символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ddece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prnt_txt(model):\n",
    "    # pick a random seed\n",
    "    start = np.random.randint(0, len(dataX)-1)\n",
    "    pattern = dataX[start]\n",
    "    print (\"Seed:\")\n",
    "    print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "    \n",
    "    # generate characters\n",
    "    for i in range(1000):\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = x / float(n_vocab)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_char[index]\n",
    "        seq_in = [int_to_char[value] for value in pattern]\n",
    "        sys.stdout.write(result)\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e88c87f",
   "metadata": {},
   "source": [
    "Затем нам нужно загрузить текст ASCII для книги в память и преобразовать все символы в нижний регистр, чтобы уменьшить словарный запас, который должна выучить сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9082f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4c76e",
   "metadata": {},
   "source": [
    "Преобразуем символы в числа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9bbf6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f3a85",
   "metadata": {},
   "source": [
    "Суммируем набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893dd818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144430\n",
      "Total Vocab:  45\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68af8b",
   "metadata": {},
   "source": [
    "Разделяя книгу на последовательности, конвертируем символы в целые числа,\n",
    "используя нашу таблицу поиска, которую подготовили ранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91948ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  144330\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3c46f5",
   "metadata": {},
   "source": [
    "Преобразуем выходные шаблоны в одну кодировку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf75e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27796ad",
   "metadata": {},
   "source": [
    "Создадим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f01c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a7201",
   "metadata": {},
   "source": [
    "Определим чекпоинты для того чтобы модель работала быстрей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a232953",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "callbacks=[MyCallback()]\n",
    "callbacks.append(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea92253",
   "metadata": {},
   "source": [
    "Обучим модель использую встроеный колбек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0502ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.5208End epoch 0 of training\n",
      "Seed:\n",
      "\" othing to what i could say if i chose,' the duchess replied, in\n",
      "a pleased tone.\n",
      "\n",
      "'pray don't trouble \"\n",
      " to the wooe the cane to the cane to the cane to the care to the care to the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care the care \n",
      "Done.\n",
      "\n",
      "Epoch 1: loss improved from 2.86235 to 2.52083, saving model to weights-improvement-01-2.5208.hdf5\n",
      "1128/1128 [==============================] - 154s 136ms/step - loss: 2.5208\n",
      "Epoch 2/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 2.3228End epoch 1 of training\n",
      "Seed:\n",
      "\"  great hall, with the glass table and the little door,\n",
      "had vanished completely.\n",
      "\n",
      "very soon the rabbi \"\n",
      "t to the was of the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutters the coutt\n",
      "Done.\n",
      "\n",
      "Epoch 2: loss improved from 2.52083 to 2.32282, saving model to weights-improvement-02-2.3228.hdf5\n",
      "1128/1128 [==============================] - 155s 137ms/step - loss: 2.3228\n",
      "Epoch 3/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 2.1791End epoch 2 of training\n",
      "Seed:\n",
      "\" .\n",
      "\n",
      "alice did not quite know what to say to this: so she helped herself\n",
      "to some tea and bread-and-but \"\n",
      " the was oot of the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the \n",
      "Done.\n",
      "\n",
      "Epoch 3: loss improved from 2.32282 to 2.17918, saving model to weights-improvement-03-2.1792.hdf5\n",
      "1128/1128 [==============================] - 154s 137ms/step - loss: 2.1792\n",
      "Epoch 4/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 2.0823End epoch 3 of training\n",
      "Seed:\n",
      "\" actly\n",
      "what they said.\n",
      "\n",
      "the executioner's argument was, that you couldn't cut off a head unless\n",
      "there \"\n",
      " sas the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the could the c\n",
      "Done.\n",
      "\n",
      "Epoch 4: loss improved from 2.17918 to 2.08231, saving model to weights-improvement-04-2.0823.hdf5\n",
      "1128/1128 [==============================] - 151s 134ms/step - loss: 2.0823\n",
      "Epoch 5/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 2.0020End epoch 4 of training\n",
      "Seed:\n",
      "\" they\n",
      "liked, so that it was not easy to know when the race was over. however,\n",
      "when they had been runn \"\n",
      "ed to her hard and the was so the was so the was so the was so the was so the was so the was so the was so the was so the was of the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit sas the could the sabbit \n",
      "Done.\n",
      "\n",
      "Epoch 5: loss improved from 2.08231 to 2.00207, saving model to weights-improvement-05-2.0021.hdf5\n",
      "1128/1128 [==============================] - 162s 144ms/step - loss: 2.0021\n",
      "Epoch 6/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.9389End epoch 5 of training\n",
      "Seed:\n",
      "\"  has just been picked\n",
      "up.'\n",
      "\n",
      "'what's in it?' said the queen.\n",
      "\n",
      "'i haven't opened it yet,' said the whi \"\n",
      "te rabbit, 'and the sooe of the mittle she of the cane of the cane of the cane. \n",
      "'io to de a little sooe,  she was a little sooe of the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said to her hard and the cane of the cane, and the was not a little said \n",
      "Done.\n",
      "\n",
      "Epoch 6: loss improved from 2.00207 to 1.93887, saving model to weights-improvement-06-1.9389.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128/1128 [==============================] - 154s 137ms/step - loss: 1.9389\n",
      "Epoch 7/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.8800End epoch 6 of training\n",
      "Seed:\n",
      "\" t of his\n",
      "pocket, and was looking at it uneasily, shaking it every now and then,\n",
      "and holding it to hi \"\n",
      "s hard and the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of t\n",
      "Done.\n",
      "\n",
      "Epoch 7: loss improved from 1.93887 to 1.88000, saving model to weights-improvement-07-1.8800.hdf5\n",
      "1128/1128 [==============================] - 153s 135ms/step - loss: 1.8800\n",
      "Epoch 8/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.8371End epoch 7 of training\n",
      "Seed:\n",
      "\" d got\n",
      "its neck nicely straightened out, and was going to give the hedgehog a\n",
      "blow with its head, it  \"\n",
      "was to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to the tabbit was a little bod to t\n",
      "Done.\n",
      "\n",
      "Epoch 8: loss improved from 1.88000 to 1.83716, saving model to weights-improvement-08-1.8372.hdf5\n",
      "1128/1128 [==============================] - 151s 134ms/step - loss: 1.8372\n",
      "Epoch 9/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.7945End epoch 8 of training\n",
      "Seed:\n",
      "\" ' said alice thoughtfully: 'but then--i\n",
      "shouldn't be hungry for it, you know.'\n",
      "\n",
      "'not at first, perha \"\n",
      "ts,' she mock turtle reimed in a long tore, and the tas out of the thing was a little shated the had bean to the tabbit, and the tas of the tabbit in a long tay of the thing was a little shated the had bean to the tabbit, and the tas of the tabbit in a long tay of the thing was a little shated the had bean to the tabbit, and the tas of the tabbit in a long tay of the thing was a little shated the had bean to the tabbit, and the tas of the tabbit in a long tay of the thing was a little shated the had bean to the tabbit, and the tas of the tabbit in a long tay of the thing was a little shated the had bean to the tabbit, and the tas of the tabbit in a long tay of the thing was a little shated the had bean to the tabbit, and the tas of the tabbit in a long tay of the thing was a little shated the had bean to the tabbit, and the tas of the tabbit in a long tay of the thing was a little shated the had bean to the tabbit, and the tas of the tabbit in a long tay of the thing was a little shate\n",
      "Done.\n",
      "\n",
      "Epoch 9: loss improved from 1.83716 to 1.79456, saving model to weights-improvement-09-1.7946.hdf5\n",
      "1128/1128 [==============================] - 150s 133ms/step - loss: 1.7946\n",
      "Epoch 10/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.7570End epoch 9 of training\n",
      "Seed:\n",
      "\" t words,' said poor alice, and her eyes\n",
      "filled with tears again as she went on, 'i must be mabel aft \"\n",
      "ter to the words ' \n",
      "'i mever have the fanees whth the mittle siie,' said the cuchess; 'i mever have the fanee of the courte ' \n",
      "'i mever have the fanees whth the mittle siie,' said the cuchess; 'i mever have the fanee of the courte ' \n",
      "'i mever have the fanees whth the mittle siie,' said the cuchess; 'i mever have the fanee of the courte ' \n",
      "'i mever have the fanees whth the mittle siie,' said the cuchess; 'i mever have the fanee of the courte ' \n",
      "'i mever have the fanees whth the mittle siie,' said the cuchess; 'i mever have the fanee of the courte ' \n",
      "'i mever have the fanees whth the mittle siie,' said the cuchess; 'i mever have the fanee of the courte ' \n",
      "'i mever have the fanees whth the mittle siie,' said the cuchess; 'i mever have the fanee of the courte ' \n",
      "'i mever have the fanees whth the mittle siie,' said the cuchess; 'i mever have the fanee of the courte ' \n",
      "'i mever have the fanees whth the mittle siie,' said the cuchess; 'i mever have the fanee of the courte ' \n",
      "'i mever have the\n",
      "Done.\n",
      "\n",
      "Epoch 10: loss improved from 1.79456 to 1.75693, saving model to weights-improvement-10-1.7569.hdf5\n",
      "1128/1128 [==============================] - 150s 133ms/step - loss: 1.7569\n",
      "Epoch 11/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.7203End epoch 10 of training\n",
      "Seed:\n",
      "\" it except a tiny golden key, and alice's\n",
      "first thought was that it might belong to one of the doors  \"\n",
      "of the coorsess. \n",
      "\n",
      "'i mever tas the mock turtle,' said the mock turtle. \n",
      "'i m a pueer to the thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond the mittle thing ' said the mock turtle. \n",
      "'i m a cond \n",
      "Done.\n",
      "\n",
      "Epoch 11: loss improved from 1.75693 to 1.72054, saving model to weights-improvement-11-1.7205.hdf5\n",
      "1128/1128 [==============================] - 151s 134ms/step - loss: 1.7205\n",
      "Epoch 12/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.6901End epoch 11 of training\n",
      "Seed:\n",
      "\" iting to put his shoes on.\n",
      "\n",
      "'--and just take his head off outside,' the queen added to one of the\n",
      "of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpced of the thoes tay oo the was oot of the was oot of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of the was out of\n",
      "Done.\n",
      "\n",
      "Epoch 12: loss improved from 1.72054 to 1.69023, saving model to weights-improvement-12-1.6902.hdf5\n",
      "1128/1128 [==============================] - 153s 135ms/step - loss: 1.6902\n",
      "Epoch 13/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.6568End epoch 12 of training\n",
      "Seed:\n",
      "\" atever happens. what will become of me?'\n",
      "\n",
      "luckily for alice, the little magic bottle had now had its \"\n",
      "t as she was so she was she was oot a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a little shater and she had not a li\n",
      "Done.\n",
      "\n",
      "Epoch 13: loss improved from 1.69023 to 1.65697, saving model to weights-improvement-13-1.6570.hdf5\n",
      "1128/1128 [==============================] - 150s 133ms/step - loss: 1.6570\n",
      "Epoch 14/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.6325End epoch 13 of training\n",
      "Seed:\n",
      "\" tells us a story.'\n",
      "\n",
      "'i'm afraid i don't know one,' said alice, rather alarmed at the\n",
      "proposal.\n",
      "\n",
      "'the \"\n",
      "n you con't know the sook ' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't know the sook of the mock turtle,' said the mock turtle. \n",
      "'i don't kn\n",
      "Done.\n",
      "\n",
      "Epoch 14: loss improved from 1.65697 to 1.63254, saving model to weights-improvement-14-1.6325.hdf5\n",
      "1128/1128 [==============================] - 150s 133ms/step - loss: 1.6325\n",
      "Epoch 15/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.6109End epoch 14 of training\n",
      "Seed:\n",
      "\" tle with a sigh. 'i\n",
      "only took the regular course.'\n",
      "\n",
      "'what was that?' inquired alice.\n",
      "\n",
      "'reeling and w \"\n",
      "hich way ' said the mock turtle in a low of the cook of the cook of the wonder and the cook was oo the wonder as the could, and she was not a little shme whth the was oot and then the was oot as the was oo the court, and she was not a little shme whth the was oot and then the was oot as the was oo the court, and she was not a little shme whth the was oot and then the was oot as the was oo the court, and she was not a little shme whth the was oot and then the was oot as the was oo the court, and she was not a little shme whth the was oot and then the was oot as the was oo the court, and she was not a little shme whth the was oot and then the was oot as the was oo the court, and she was not a little shme whth the was oot and then the was oot as the was oo the court, and she was not a little shme whth the was oot and then the was oot as the was oo the court, and she was not a little shme whth the was oot and then the was oot as the was oo the court, and she was not a little shme whth the \n",
      "Done.\n",
      "\n",
      "Epoch 15: loss improved from 1.63254 to 1.61086, saving model to weights-improvement-15-1.6109.hdf5\n",
      "1128/1128 [==============================] - 150s 133ms/step - loss: 1.6109\n",
      "Epoch 16/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.5863End epoch 15 of training\n",
      "Seed:\n",
      "\" id the hatter: 'i'm on the floor, as it is.'\n",
      "\n",
      "'then you may sit down,' the king replied.\n",
      "\n",
      "here the o \"\n",
      "oor little shings and she coor was to she was not a little shinghe of the coor, and she was not a little shinghe of the coor and then the datt cat of the cook was out of the way of the cook with a shing way of the cook with a shing way of the cook was of the cook with a shing way of the cook was of the cook of the coor and then the doom was so the thoe whth the door with a shing way of the cook was of the cook with a shing way of the cook was of the cook of the coor and then the doom was so the thoe whth the door with a shing way of the cook was of the cook with a shing way of the cook was of the cook of the coor and then the doom was so the thoe whth the door with a shing way of the cook was of the cook with a shing way of the cook was of the cook of the coor and then the doom was so the thoe whth the door with a shing way of the cook was of the cook with a shing way of the cook was of the cook of the coor and then the doom was so the thoe whth the door with a shing way of the cook wa\n",
      "Done.\n",
      "\n",
      "Epoch 16: loss improved from 1.61086 to 1.58631, saving model to weights-improvement-16-1.5863.hdf5\n",
      "1128/1128 [==============================] - 150s 133ms/step - loss: 1.5863\n",
      "Epoch 17/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.5600End epoch 16 of training\n",
      "Seed:\n",
      "\" to get through\n",
      "the door, she ran out of the house, and found quite a crowd of little\n",
      "animals and bir \"\n",
      "ccted to see it was a little bod and the courte of the louse was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words she was a little shghed out of the words \n",
      "Done.\n",
      "\n",
      "Epoch 17: loss improved from 1.58631 to 1.56002, saving model to weights-improvement-17-1.5600.hdf5\n",
      "1128/1128 [==============================] - 151s 134ms/step - loss: 1.5600\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.5442End epoch 17 of training\n",
      "Seed:\n",
      "\" rm.\n",
      "\n",
      "'a fine day, your majesty!' the duchess began in a low, weak voice.\n",
      "\n",
      "'now, i give you fair warn \"\n",
      "ed the boutt,' said the king, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the hatter was see the court, and she was not a little boutte of the court, and the ha\n",
      "Done.\n",
      "\n",
      "Epoch 18: loss improved from 1.56002 to 1.54430, saving model to weights-improvement-18-1.5443.hdf5\n",
      "1128/1128 [==============================] - 151s 134ms/step - loss: 1.5443\n",
      "Epoch 19/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.5195End epoch 18 of training\n",
      "Seed:\n",
      "\" moment they saw her, they hurried\n",
      "back to the game, the queen merely remarking that a moment's delay \"\n",
      " with the cance.\n",
      "\n",
      "'wou dan't have to be tr to she would ' said the caterpillar.\n",
      "\n",
      "'i must be talk it a little sat of the mocster sat ' said the mock turtle. ''--bnd the morter to she would be she lobk turtle,' said the caterpillar.\n",
      "\n",
      "'well, i shall have to be a long arme way of a long and a little say of the mock turtle,' said the mock turtle. \n",
      "'i mooy all that iave to be tr to she would ' said the caterpillar.\n",
      "\n",
      "'i must be talk it a little sat of the mocster sat ' said the mock turtle. ''--bnd the morter to she would be she lobk turtle,' said the caterpillar.\n",
      "\n",
      "'well, i shall have to be a long arme way of a long and a little say of the mock turtle,' said the mock turtle. \n",
      "'i mooy all that iave to be tr to she would ' said the caterpillar.\n",
      "\n",
      "'i must be talk it a little sat of the mocster sat ' said the mock turtle. ''--bnd the morter to she would be she lobk turtle,' said the caterpillar.\n",
      "\n",
      "'well, i shall have to be a long arme way of a long and a little say of the mock turtle,' said the moc\n",
      "Done.\n",
      "\n",
      "Epoch 19: loss improved from 1.54430 to 1.51963, saving model to weights-improvement-19-1.5196.hdf5\n",
      "1128/1128 [==============================] - 151s 134ms/step - loss: 1.5196\n",
      "Epoch 20/20\n",
      "1127/1128 [============================>.] - ETA: 0s - loss: 1.5011End epoch 19 of training\n",
      "Seed:\n",
      "\" ut i shall have to ask them what the name of the country\n",
      "is, you know. please, ma'am, is this new ze \"\n",
      "se the boot and she was to she thing a little botters. \n",
      "\n",
      "'i mever said that ' said the mouse, and tan see the coumouse so she was oot a little bowr of the was oot again, and she was not a little book and then the coor with the mouse was so she thought it was a little bowttered to see it as the court, and she was not a little book and then the coor with the mouse was so she thought it was a little bowttered to see it as the court, and she was not a little book and then the coor with the mouse was so she thought it was a little bowttered to see it as the court, and she was not a little book and then the coor with the mouse was so she thought it was a little bowttered to see it as the court, and she was not a little book and then the coor with the mouse was so she thought it was a little bowttered to see it as the court, and she was not a little book and then the coor with the mouse was so she thought it was a little bowttered to see it as the court, and she was not a little book and then\n",
      "Done.\n",
      "\n",
      "Epoch 20: loss improved from 1.51963 to 1.50115, saving model to weights-improvement-20-1.5011.hdf5\n",
      "1128/1128 [==============================] - 151s 133ms/step - loss: 1.5011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb274b94f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173615b",
   "metadata": {},
   "source": [
    "Сгенерируем текст на основе последней контрольной точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb1fd3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" d she's\n",
      "such a capital one for catching mice--oh, i beg your pardon!' cried\n",
      "alice again, for this ti \"\n",
      "me they were tery like the door and taid to alice, and said to alice to herself 'the sueen side of the mors, and the morse was a little bottle would be a long say that the was anlther tore, and the cook was sert the white rabbit into the door and taid to alice, and said to alice to herself 'the sueen side of the mors, and the morse was a little bottle would be a long say that the was anlther tore, and the cook was sert the white rabbit into the door and taid to alice, and said to alice to herself 'the sueen side of the mors, and the morse was a little bottle would be a long say that the was anlther tore, and the cook was sert the white rabbit into the door and taid to alice, and said to alice to herself 'the sueen side of the mors, and the morse was a little bottle would be a long say that the was anlther tore, and the cook was sert the white rabbit into the door and taid to alice, and said to alice to herself 'the sueen side of the mors, and the morse was a little bottle would be a lo\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "filename = \"weights-improvement-20-1.5011.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "prnt_txt(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
